from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import os
import re
import pandas as pd
import pdfplumber
import spacy
from sentence_transformers import SentenceTransformer, util
import fitz  # PyMuPDF
import numpy as np
from collections import defaultdict
from datetime import datetime
import tempfile
import io
import logging
from werkzeug.utils import secure_filename
import requests
import json
import hashlib
import uuid
from threading import Thread
import time

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app, origins=["http://localhost:3000", "http://127.0.0.1:3000"])

# Configuration
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'pdf', 'xlsx', 'xls', 'csv'}
OUTPUT_CSV = "all_extracted_kpis.csv"
OUTPUT_EXCEL = "all_extracted_kpis.xlsx"

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 200 * 1024 * 1024  # 200MB max

# Cr√©er le dossier uploads s'il n'existe pas
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Charger les mod√®les NLP au d√©marrage
print("Chargement des mod√®les NLP...")
try:
    nlp = spacy.load("en_core_web_sm")
    nlp.max_length = 3000000
except OSError:
    print("T√©l√©chargement du mod√®le spaCy...")
    os.system("python -m spacy download en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")
    nlp.max_length = 3000000

kpi_model = SentenceTransformer('all-MiniLM-L6-v2')

# =============================================================================
# CLASSE CHATBOT ESG INTELLIGENT AVEC R√âPONSES D√âTAILL√âES
# =============================================================================

class ESGIntelligentChatbot:
    def __init__(self):
        self.ollama_available = False
        self.current_model = "mistral"
        self.initialize_ollama()
        
        # Contexte ESG sp√©cialis√© enrichi
        self.esg_context = self._load_enhanced_esg_knowledge_base()
        
    def _load_enhanced_esg_knowledge_base(self):
        """Base de connaissances ESG enrichie pour le chatbot"""
        return {
            "sector_benchmarks": {
                "technologie": {"ghg_emissions": "50-100 tCO2e/M‚Ç¨", "gender_diversity": "35-45%", "board_independence": "60-70%"},
                "industrie": {"ghg_emissions": "200-500 tCO2e/M‚Ç¨", "gender_diversity": "25-35%", "board_independence": "50-60%"},
                "finance": {"ghg_emissions": "20-50 tCO2e/M‚Ç¨", "gender_diversity": "40-50%", "board_independence": "70-80%"},
                "√©nergie": {"ghg_emissions": "500-1000 tCO2e/M‚Ç¨", "gender_diversity": "20-30%", "board_independence": "55-65%"}
            },
            "regulations": {
                "CSRD": "Entr√©e en vigueur 2024 pour les grandes entreprises",
                "SFDR": "R√®glement sur la publication d'informations en mati√®re de durabilit√©",
                "Taxonomie UE": "Classification des activit√©s durables",
                "Loi Climat": "Exigences renforc√©es de reporting climatique"
            },
            "best_practices": {
                "high_performance": "Int√©gration ESG dans la strat√©gie business, objectifs scientifiques valid√©s, reporting transparent",
                "medium_performance": "Syst√®mes de collecte √©tablis, initiatives ponctuelles, conformit√© r√©glementaire",
                "low_performance": "Approche r√©active, donn√©es fragment√©es, risque r√©glementaire √©lev√©"
            }
        }
    
    def initialize_ollama(self):
        """Initialise la connexion √† Ollama"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=10)
            if response.status_code == 200:
                self.ollama_available = True
                logger.info("‚úÖ Ollama disponible pour le chatbot ESG")
            else:
                logger.warning("‚ùå Ollama non accessible")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ollama non disponible: {e}")
    
    def generate_esg_insight(self, kpi_data, company_data, user_question):
        """G√©n√®re des insights ESG intelligents avec r√©ponses d√©taill√©es"""
        try:
            # Pr√©parer le contexte des donn√©es
            context = self._build_comprehensive_esg_context(kpi_data, company_data, user_question)
            
            if not self.ollama_available:
                return self._generate_enhanced_detailed_insight(kpi_data, company_data, user_question, context)
            
            prompt = f"""En tant qu'expert senior en analyse ESG avec plus de 15 ans d'exp√©rience, je vous propose une analyse approfondie bas√©e sur les donn√©es disponibles.

CONTEXTE D'ANALYSE:
{context}

QUESTION SP√âCIFIQUE: {user_question}

Veuillez fournir une r√©ponse structur√©e en paragraphes d√©taill√©s qui :

1. Commence par une analyse positionnelle de l'entreprise dans son secteur
2. D√©taille les forces et faiblesses identifi√©es avec des exemples concrets
3. Explique les implications strat√©giques et r√©glementaires
4. Propose des recommandations actionnables avec des √©ch√©ances r√©alistes
5. Mentionne les risques et opportunit√©s sp√©cifiques

√âvitez les listes √† puces et privil√©giez des paragraphes fluides et connect√©s. Utilisez un langage professionnel mais accessible, avec des r√©f√©rences aux r√©glementations pertinentes (CSRD, SFDR, Taxonomie UE).

Analyse experte ESG:"""

            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": self.current_model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 1200
                    }
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                return self._format_detailed_response(result.get('response', ''))
            else:
                return self._generate_enhanced_detailed_insight(kpi_data, company_data, user_question, context)
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration insight ESG: {e}")
            return self._generate_enhanced_detailed_insight(kpi_data, company_data, user_question, "")
    
    def _format_detailed_response(self, response):
        """Formate la r√©ponse pour assurer des paragraphes coh√©rents"""
        # Nettoyer et structurer la r√©ponse
        paragraphs = [p.strip() for p in response.split('\n\n') if p.strip()]
        formatted_response = '\n\n'.join(paragraphs)
        return formatted_response
    
    def _build_comprehensive_esg_context(self, kpi_data, company_data, user_question):
        """Construit un contexte ESG complet et d√©taill√©"""
        context_parts = []
        
        # Analyse quantitative d√©taill√©e
        if not kpi_data.empty:
            total_kpis = len(kpi_data)
            avg_confidence = kpi_data['confidence'].mean()
            high_confidence_kpis = len(kpi_data[kpi_data['confidence'] > 0.7])
            medium_confidence_kpis = len(kpi_data[(kpi_data['confidence'] > 0.4) & (kpi_data['confidence'] <= 0.7)])
            low_confidence_kpis = len(kpi_data[kpi_data['confidence'] <= 0.4])
            
            context_parts.append("ANALYSE QUANTITATIVE DES DONN√âES ESG:")
            context_parts.append(f"L'ensemble de donn√©es comprend {total_kpis} indicateurs ESG distincts, avec un niveau de confiance moyen de {avg_confidence:.1%}. Parmi ceux-ci, {high_confidence_kpis} indicateurs pr√©sentent une fiabilit√© √©lev√©e (confiance > 70%), {medium_confidence_kpis} une fiabilit√© moyenne, et {low_confidence_kpis} indicateurs n√©cessitent une v√©rification approfondie en raison de leur faible niveau de confiance.")
        
        # Analyse qualitative par domaine
        if 'topic_fr' in kpi_data.columns:
            domain_analysis = kpi_data['topic_fr'].value_counts()
            context_parts.append("\nCOUVERTURE TH√âMATIQUE D√âTAILL√âE:")
            
            domain_descriptions = []
            for domain, count in domain_analysis.items():
                if count >= 5:
                    domain_descriptions.append(f"une couverture robuste dans le domaine {domain} avec {count} indicateurs sp√©cifiques")
                elif count >= 2:
                    domain_descriptions.append(f"une pr√©sence mod√©r√©e en {domain} ({count} indicateurs)")
                else:
                    domain_descriptions.append(f"une couverture limit√©e pour {domain}")
            
            context_parts.append("L'entreprise d√©montre " + ", ".join(domain_descriptions) + ".")
        
        # Analyse des performances
        if not kpi_data.empty and 'confidence' in kpi_data.columns:
            top_kpis = kpi_data.nlargest(3, 'confidence')
            bottom_kpis = kpi_data.nsmallest(3, 'confidence')
            
            context_parts.append("\nINDICATEURS √Ä FORTE FIABILIT√â:")
            top_descriptions = []
            for _, kpi in top_kpis.iterrows():
                top_descriptions.append(f"l'indicateur {kpi.get('kpi_name', 'N/A')} avec une valeur de {kpi.get('value', 'N/A')} {kpi.get('unit', '')} et un score de confiance de {kpi.get('confidence', 0):.1%}")
            context_parts.append("Parmi les donn√©es les plus fiables figurent " + ", ".join(top_descriptions) + ".")
            
            context_parts.append("\nINDICATEURS REQU√âRANT UNE ATTENTION PARTICULI√àRE:")
            bottom_descriptions = []
            for _, kpi in bottom_kpis.iterrows():
                bottom_descriptions.append(f"{kpi.get('kpi_name', 'N/A')} (confiance: {kpi.get('confidence', 0):.1%})")
            context_parts.append("Certains indicateurs pr√©sentent des niveaux de confiance n√©cessitant une validation renforc√©e, notamment " + ", ".join(bottom_descriptions) + ".")
        
        # Contexte entreprise et sectoriel
        if company_data:
            context_parts.append(f"\nCONTEXTE STRAT√âGIQUE:")
            company_context = []
            for key, value in company_data.items():
                company_context.append(f"{key}: {value}")
            context_parts.append("Le profil de l'entreprise se caract√©rise par " + ", ".join(company_context) + ".")
        
        # Ajouter des insights sectoriels
        estimated_sector = self._estimate_company_sector(kpi_data)
        sector_insights = self._get_sector_insights(estimated_sector)
        context_parts.append(f"\nPERSPECTIVE SECTORIELLE:")
        context_parts.append(f"Bas√© sur le profil des indicateurs, l'entreprise √©volue probablement dans le secteur {estimated_sector}. {sector_insights}")
        
        return "\n".join(context_parts)
    
    def _estimate_company_sector(self, kpi_data):
        """Estime le secteur d'activit√© bas√© sur les KPIs"""
        if kpi_data.empty:
            return "non d√©termin√©"
            
        environmental_count = len(kpi_data[kpi_data['topic_fr'].str.contains('environnement|√©mis|√©nergie', na=False, case=False)])
        social_count = len(kpi_data[kpi_data['topic_fr'].str.contains('social|diversit√©|employ√©', na=False, case=False)])
        total_count = len(kpi_data)
        
        env_ratio = environmental_count / total_count if total_count > 0 else 0
        social_ratio = social_count / total_count if total_count > 0 else 0
        
        if env_ratio > 0.6:
            return "industriel ou √©nerg√©tique"
        elif social_ratio > 0.5:
            return "services ou technologies"
        elif env_ratio > 0.3 and social_ratio > 0.3:
            return "manufacturier diversifi√©"
        else:
            return "g√©n√©ral"
    
    def _get_sector_insights(self, sector):
        """Retourne des insights sp√©cifiques au secteur"""
        insights = {
            "industriel ou √©nerg√©tique": "Ce secteur fait face √† des exigences r√©glementaires croissantes en mati√®re d'√©missions et d'efficacit√© √©nerg√©tique, avec une attention particuli√®re sur la transition bas-carbone et l'√©conomie circulaire.",
            "services ou technologies": "Les enjeux prioritaires incluent la diversit√© des √©quipes, l'innovation responsable, et la gouvernance des donn√©es, avec des attentes croissantes en mati√®re de transparence.",
            "manufacturier diversifi√©": "La double pression environnementale et sociale caract√©rise ce secteur, n√©cessitant une approche √©quilibr√©e entre r√©duction d'impact et d√©veloppement des talents.",
            "g√©n√©ral": "Une approche ESG progressive est recommand√©e, en commen√ßant par les domaines √† impact mat√©riel le plus √©lev√© pour l'activit√© sp√©cifique de l'entreprise."
        }
        return insights.get(sector, "Une analyse sectorielle plus pr√©cise n√©cessiterait des informations compl√©mentaires sur le c≈ìur d'activit√© de l'entreprise.")
    
    def _generate_enhanced_detailed_insight(self, kpi_data, company_data, user_question, context=""):
        """G√©n√®re un insight d√©taill√© am√©lior√© avec paragraphes structur√©s"""
        
        if kpi_data.empty:
            return self._get_contextual_fallback_response(user_question)
        
        # Analyse quantitative de base
        total_kpis = len(kpi_data)
        avg_confidence = kpi_data['confidence'].mean()
        high_conf_count = len(kpi_data[kpi_data['confidence'] > 0.7])
        medium_conf_count = len(kpi_data[(kpi_data['confidence'] > 0.4) & (kpi_data['confidence'] <= 0.7)])
        low_conf_count = len(kpi_data[kpi_data['confidence'] <= 0.4])
        
        # Construction de la r√©ponse en paragraphes d√©taill√©s
        response_parts = []
        
        # Introduction contextuelle
        response_parts.append(
            f"En ma qualit√© d'expert ESG senior, j'ai analys√© en profondeur les {total_kpis} indicateurs disponibles "
            f"pour vous fournir une √©valuation d√©taill√©e et personnalis√©e. La qualit√© globale des donn√©es pr√©sente "
            f"un niveau de confiance moyen de {avg_confidence:.1%}, ce qui se traduit par {high_conf_count} indicateurs "
            f"√† haute fiabilit√©, {medium_conf_count} √† fiabilit√© mod√©r√©e, et {low_conf_count} indicateurs n√©cessitant "
            f"une attention particuli√®re en raison de leur niveau de confiance plus limit√©."
        )
        
        # Analyse sectorielle et positionnement
        estimated_sector = self._estimate_company_sector(kpi_data)
        response_parts.append(
            f"Sur la base du profil des indicateurs analys√©s, votre organisation √©volue probablement dans le secteur "
            f"{estimated_sector}. Cette appr√©ciation sectorielle permet de contextualiser vos performances ESG au regard "
            f"des attentes sp√©cifiques et des standards de votre industrie, notamment en mati√®re d'intensit√© carbone, "
            f"de diversit√© des √©quipes et de gouvernance d'entreprise."
        )
        
        # Analyse par domaine d√©taill√©e
        if 'topic_fr' in kpi_data.columns:
            domain_stats = kpi_data['topic_fr'].value_counts()
            primary_domains = domain_stats.head(3)
            
            domain_analysis = "En examinant la r√©partition th√©matique, votre entreprise pr√©sente "
            domain_details = []
            for domain, count in primary_domains.items():
                if count >= 5:
                    domain_details.append(f"une ma√Ætrise avanc√©e du domaine {domain} mat√©rialis√©e par {count} indicateurs d√©di√©s")
                elif count >= 2:
                    domain_details.append(f"une couverture op√©rationnelle en {domain} avec {count} indicateurs de suivi")
                else:
                    domain_details.append(f"une pr√©sence √©mergente dans le domaine {domain}")
            
            response_parts.append(domain_analysis + ", ".join(domain_details) + ". Cette cartographie refl√®te les priorit√©s strat√©giques actuelles et identifie les axes de d√©veloppement potentiels pour une couverture ESG plus exhaustive.")
        
        # √âvaluation de la maturit√© ESG approfondie
        if avg_confidence > 0.7:
            maturity_assessment = (
                "Le niveau de maturit√© ESG appara√Æt particuli√®rement avanc√©, t√©moignant de syst√®mes de collecte "
                "robustes et d'une culture de transparence bien ancr√©e. Cette excellence op√©rationnelle constitue "
                "un atout strat√©gique majeur pour anticiper les √©volutions r√©glementaires comme le CSRD et positionner "
                "l'entreprise comme r√©f√©rence dans son secteur. La prochaine √©tape pourrait consister √† d√©velopper "
                "des indicateurs d'impact plus avanc√©s et √† int√©grer les consid√©rations ESG dans l'ensemble de la "
                "cha√Æne de valeur."
            )
        elif avg_confidence > 0.5:
            maturity_assessment = (
                "La maturit√© ESG se situe √† un stade interm√©diaire, indiquant des fondations solides mais "
                "des opportunit√©s significatives d'optimisation. Les processus de collecte sont √©tablis mais "
                "gagneraient en automatisation et en standardisation. Cette position offre l'avantage d'une "
                "base op√©rationnelle fiable tout en permettant une mont√©e en comp√©tence progressive vers "
                "l'excellence ESG. Les efforts devraient prioriser la consolidation des donn√©es sociales "
                "et environnementales, ainsi que leur int√©gration dans les m√©canismes de d√©cision strat√©gique."
            )
        else:
            maturity_assessment = (
                "Le stade de d√©veloppement ESG est actuellement √©mergent, soulignant la n√©cessit√© d'investissements "
                "structurants dans les syst√®mes de mesure et la gouvernance associ√©e. Cette situation, bien que "
                "repr√©sentant un d√©fi imm√©diat, offre l'opportunit√© de construire une d√©marche ESG coh√©rente "
                "et align√©e avec la strat√©gie business. Une approche prioris√©e ciblant initialement les domaines "
                "les plus mat√©riels pour l'activit√© permettrait des progr√®s rapides et visibles, tout en "
                "posant les bases d'une transformation plus profonde."
            )
        
        response_parts.append(maturity_assessment)
        
        # Recommandations strat√©giques contextuelles
        recommendations = self._generate_strategic_recommendations(kpi_data, user_question, avg_confidence)
        response_parts.append(recommendations)
        
        # Perspectives r√©glementaires
        regulatory_outlook = self._get_regulatory_outlook(estimated_sector)
        response_parts.append(regulatory_outlook)
        
        return "\n\n".join(response_parts)
    
    def _generate_strategic_recommendations(self, kpi_data, user_question, avg_confidence):
        """G√©n√®re des recommandations strat√©giques contextuelles"""
        question_lower = user_question.lower()
        
        if any(word in question_lower for word in ['positionnement', 'comparer', 'secteur', 'benchmark']):
            return (
                "Pour affiner votre positionnement sectoriel, je recommande la mise en place d'une analyse comparative "
                "syst√©matique int√©grant √† la fois les r√©f√©rentiels standards du secteur et les pratiques √©mergentes "
                "des leaders ESG. Cette d√©marche devrait s'accompagner d'un dialogue renforc√© avec les parties prenantes "
                "cl√©s pour identifier les attentes sp√©cifiques et les crit√®res de diff√©renciation valoris√©s. La cr√©ation "
                "d'un tableau de bord de benchmarking permettrait un suivi dynamique de votre position relative et "
                "l'identification rapide des domaines n√©cessitant une attention particuli√®re."
            )
        
        elif any(word in question_lower for word in ['performance', 'r√©sultat', 'am√©lioration']):
            return (
                "L'optimisation des performances ESG devrait s'articuler autour d'une approche duale combinant "
                "le renforcement de la fiabilit√© des donn√©es existantes et l'√©largissement strat√©gique de la couverture "
                "th√©matique. Concernant la qualit√© des donn√©es, un programme de validation multi-niveaux incluant "
                "des audits ponctuels et des contr√¥les crois√©s permettrait d'atteindre un niveau d'excellence. "
                "Parall√®lement, l'identification des domaines ESG mat√©riels pour votre mod√®le d'affaires guidera "
                "l'extension progressive du p√©rim√®tre de reporting vers des indicateurs plus avanc√©s d'impact."
            )
        
        elif any(word in question_lower for word in ['r√®glementation', 'conformit√©', 'csrd', 'sfdr']):
            return (
                "Au regard de l'√©volution rapide du paysage r√©glementaire, une cartographie exhaustive des exigences "
                "applicables s'impose, en particulier pour le CSRD qui repr√©sente une transformation majeure des "
                "obligations de reporting. La robustesse actuelle de vos donn√©es constitue un atout significatif "
                "pour une mise en conformit√© efficiente. Je recommande la r√©alisation d'un gap analysis d√©taill√© "
                "pour identifier pr√©cis√©ment les √©carts √† combler et l'√©laboration d'un plan de transition progressif "
                "int√©grant les √©ch√©ances r√©glementaires, les ressources n√©cessaires et les impacts op√©rationnels."
            )
        
        else:
            if avg_confidence > 0.7:
                return (
                    "La qualit√© exceptionnelle de vos donn√©es ESG ouvre la voie √† des initiatives strat√©giques "
                    "avanc√©es. Je recommande notamment le d√©veloppement d'objectifs scientifiques align√©s sur "
                    "les accords climatiques internationaux, l'int√©gration des crit√®res ESG dans les m√©canismes "
                    "de r√©mun√©ration variable, et l'exploration de financements verts pour acc√©l√©rer votre "
                    "transition durable. La prochaine √©tape consisterait √† transformer vos donn√©es en avantage "
                    "concurrentiel through une communication d'impact diff√©renciante et cr√©dible."
                )
            else:
                return (
                    "La priorit√© imm√©diate consiste √† consolider les fondations de votre d√©marche ESG through "
                    "une standardisation des processus de collecte et une clarification des responsabilit√©s "
                    "op√©rationnelles. L'√©tablissement d'un plan de progression clair avec des objectifs interm√©diaires "
                    "mesurables permettrait de maintenir l'√©lan et de d√©montrer des avanc√©es concr√®tes. "
                    "L'int√©gration des consid√©rations ESG dans la planification strat√©gique √† moyen terme "
                    "maximisera la cr√©ation de valeur durable et renforcera la r√©silience de l'organisation."
                )
    
    def _get_regulatory_outlook(self, sector):
        """Retourne les perspectives r√©glementaires par secteur"""
        outlooks = {
            "industriel ou √©nerg√©tique": (
                "Le secteur industriel et √©nerg√©tique fait face √† un renforcement significatif des exigences "
                "r√©glementaires, particuli√®rement sur les √©missions de gaz √† effet de serre et l'efficacit√© "
                "√©nerg√©tique. La taxonomie europ√©enne et le m√©canisme d'ajustement carbone aux fronti√®res "
                "vont progressivement reconfigurer les r√®gles de concurrence. Une anticipation active de "
                "ces √©volutions through l'innovation bas-carbone et l'√©conomie circulaire deviendra un "
                "facteur cl√© de comp√©titivit√© dans les prochaines ann√©es."
            ),
            "services ou technologies": (
                "Les acteurs des services et technologies doivent se pr√©parer √† une transparence accrue "
                "sur leur gouvernance des donn√©es, leur impact social et leur empreinte environnementale "
                "indirecte. Le r√®glement SFDR et les exigences de due diligence vont renforcer les attentes "
                "en mati√®re de reporting extra-financier. L'int√©gration de l'ESG dans l'innovation produit "
                "et service constituera un diff√©rentiateur strat√©gique face √† une r√©gulation de plus en plus "
                "exigeante sur la responsabilit√© num√©rique."
            ),
            "manufacturier diversifi√©": (
                "La double pression r√©glementaire environnementale et sociale caract√©rise le paysage "
                "des manufacturiers diversifi√©s. Les obligations de reporting se √©tendent progressivement "
                "√† l'ensemble de la cha√Æne d'approvisionnement, tandis que les crit√®res sociaux gagnent "
                "en importance dans les appels d'offres et les relations commerciales. Une approche "
                "proactive int√©grant l'√©coconception, l'√©conomie circulaire et le d√©veloppement des "
                "comp√©tences sera essentielle pour naviguer dans ce environnement r√©glementaire complexe."
            )
        }
        return outlooks.get(sector, 
            "Le paysage r√©glementaire ESG conna√Æt une √©volution rapide et complexe, avec une harmonisation "
            "progressive au niveau europ√©en through le CSRD et la taxonomie verte. Une veille r√©glementaire "
            "active et une approche flexible de conformit√© sont recommand√©es pour anticiper les changements "
            "et transformer les contraintes r√©glementaires en opportunit√©s strat√©giques."
        )
    
    def _get_contextual_fallback_response(self, user_question):
        """R√©ponses de fallback contextuelles et d√©taill√©es"""
        question_lower = user_question.lower()
        
        if any(word in question_lower for word in ['positionnement', 'comparer', 'benchmark']):
            return (
                "Pour √©tablir un positionnement ESG pr√©cis et personnalis√©, l'analyse n√©cessite l'acc√®s "
                "√† des donn√©es sp√©cifiques sur les performances de votre entreprise. En l'absence de ces "
                "informations, je peux vous indiquer que les organisations leaders en mati√®re ESG se "
                "caract√©risent g√©n√©ralement par une int√©gration profonde des consid√©rations de durabilit√© "
                "dans leur strat√©gie business, une transparence accrue dans leur reporting, et un engagement "
                "mesurable sur des objectifs ambitieux align√©s avec les r√©f√©rentiels internationaux. "
                "Une √©valuation personnalis√©e et actionnable n√©cessiterait l'extraction pr√©alable des "
                "indicateurs ESG pertinents √† partir de vos documents de reporting through notre syst√®me "
                "d'analyse automatis√©e."
            )
        
        elif any(word in question_lower for word in ['performance', 'r√©sultat']):
            return (
                "L'√©valuation pr√©cise de la performance ESG repose sur l'analyse syst√©matique d'indicateurs "
                "quantitatifs et qualitatifs couvrant l'ensemble des dimensions environnementales, sociales "
                "et de gouvernance. Sans donn√©es sp√©cifiques √† votre organisation, je ne peux fournir "
                "une analyse personnalis√©e, mais je peux vous orienter vers les domaines typiquement "
                "√©valu√©s dans une d√©marche ESG compl√®te : l'intensit√© carbone du scope 1, 2 et 3, "
                "la diversit√© et l'inclusion sous toutes ses dimensions, l'innovation durable, "
                "la robustesse des syst√®mes de contr√¥le interne, et l'engagement des parties prenantes. "
                "Le chargement de vos rapports ESG through notre interface permettrait une analyse "
                "d√©taill√©e et l'identification de leviers d'am√©lioration concrets."
            )
        
        else:
            return (
                "En ma qualit√© d'expert ESG disposant d'une exp√©rience approfondie dans l'analyse des "
                "performances de durabilit√© des entreprises, je suis parfaitement √©quip√© pour vous "
                "accompagner dans l'√©valuation de votre strat√©gie ESG et l'identification des opportunit√©s "
                "d'am√©lioration. Malheureusement, sans acc√®s aux donn√©es sp√©cifiques extraites de vos "
                "documents de reporting, mon analyse resterait n√©cessairement g√©n√©rique et moins "
                "pertinente pour votre contexte unique. Je vous recommande de charger vos rapports "
                "annuels, documents de durabilit√© ou tout autre document contenant des informations "
                "ESG through notre syst√®me d'extraction automatis√©e afin que je puisse vous fournir "
                "une √©valuation personnalis√©e, des recommandations concr√®tes et un plan d'action "
                "adapt√© √† votre situation sp√©cifique."
            )

    def benchmark_companies(self, companies_data):
        """R√©alise un benchmarking entre entreprises avec analyse d√©taill√©e"""
        try:
            if not companies_data:
                return "Aucune donn√©e disponible pour proc√©der √† une analyse comparative entre entreprises."
            
            benchmark_context = self._build_detailed_benchmark_context(companies_data)
            
            if not self.ollama_available:
                return self._generate_detailed_benchmark(companies_data)
            
            prompt = f"""En tant qu'expert en benchmarking ESG, r√©alisez une analyse comparative approfondie des entreprises suivantes.

DONN√âES COMPARATIVES:
{benchmark_context}

Fournissez une analyse en paragraphes structur√©s qui :

1. Compare les profils de maturit√© ESG des diff√©rentes entreprises
2. Identifie les pratiques exemplaires et les √©carts significatifs
3. Analyse les forces relatives de chaque organisation
4. Propose des recommandations de progression personnalis√©es
5. Situe les performances dans le contexte sectoriel plus large

Privil√©giez une analyse narrative fluide plut√¥t que des listes √† puces.

Analyse comparative d√©taill√©e :"""

            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": self.current_model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.2,
                        "num_predict": 1000
                    }
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                return self._format_detailed_response(result.get('response', ''))
            else:
                return self._generate_detailed_benchmark(companies_data)
                
        except Exception as e:
            logger.error(f"Erreur benchmarking: {e}")
            return self._generate_detailed_benchmark(companies_data)
    
    def _build_detailed_benchmark_context(self, companies_data):
        """Construit un contexte d√©taill√© pour le benchmarking"""
        context_parts = ["ANALYSE COMPARATIVE ESG - PROFILS DES ENTREPRISES:"]
        
        for company_name, data in companies_data.items():
            kpis = data.get('kpis', [])
            context_parts.append(f"\nEntreprise: {company_name}")
            context_parts.append(f"Nombre d'indicateurs suivis: {len(kpis)}")
            
            if kpis:
                avg_conf = sum(kpi.get('confidence', 0) for kpi in kpis) / len(kpis)
                context_parts.append(f"Niveau de confiance moyen: {avg_conf:.1%}")
                
                # Domaines couverts
                domains = set(kpi.get('topic_fr', 'G√©n√©ral') for kpi in kpis)
                context_parts.append(f"Domaines ESG couverts: {', '.join(list(domains))}")
        
        return "\n".join(context_parts)
    
    def _generate_detailed_benchmark(self, companies_data):
        """G√©n√®re un benchmarking d√©taill√© sans Ollama"""
        if not companies_data:
            return "Aucune donn√©e disponible pour r√©aliser une analyse comparative."
        
        response_parts = [
            "Analyse comparative d√©taill√©e des performances ESG entre les entreprises s√©lectionn√©es :"
        ]
        
        # Classer les entreprises par score composite
        company_scores = []
        for company_name, data in companies_data.items():
            kpis = data.get('kpis', [])
            if kpis:
                avg_conf = sum(kpi.get('confidence', 0) for kpi in kpis) / len(kpis)
                coverage = len(set(kpi.get('topic_fr', 'G√©n√©ral') for kpi in kpis))
                composite_score = avg_conf * 0.6 + (coverage / 10) * 0.4
                company_scores.append((company_name, composite_score, avg_conf, coverage, len(kpis)))
        
        if not company_scores:
            return "Les donn√©es disponibles ne permettent pas une analyse comparative significative."
        
        # Trier par score d√©croissant
        company_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Analyse des leaders
        leader_name, leader_score, leader_conf, leader_cov, leader_count = company_scores[0]
        response_parts.append(
            f"Parmi l'ensemble des entreprises analys√©es, {leader_name} se distingue nettement par la maturit√© "
            f"avanc√©e de son dispositif ESG, affichant un score de confiance moyen de {leader_conf:.1%} et "
            f"couvrant {leader_cov} domaines ESG distincts through {leader_count} indicateurs sp√©cifiques. "
            f"Cette performance t√©moigne d'une approche probablement syst√©matique et int√©gr√©e dans le management "
            f"des enjeux de durabilit√©, avec des processus de collecte robustes et une gouvernance d√©di√©e."
        )
        
        # Analyse comparative d√©taill√©e
        if len(company_scores) > 1:
            follower_name, follower_score, follower_conf, follower_cov, follower_count = company_scores[1]
            response_parts.append(
                f"En comparaison, {follower_name} pr√©sente un profil ESG √©galement solide mais avec certaines "
                f"diff√©rences notables, notamment un niveau de confiance de {follower_conf:.1%} et une couverture "
                f"de {follower_cov} domaines. Les √©carts observ√©s entre ces deux leaders sugg√®rent des approches "
                f"potentiellement diff√©rentes en mati√®re de priorisation strat√©gique des enjeux ESG et de "
                f"m√©thodologies de collecte des donn√©es. Ces variations refl√®tent souvent des contextes "
                f"op√©rationnels distincts ou des choix strat√©giques diff√©renci√©s en mati√®re de reporting."
            )
            
            if len(company_scores) > 2:
                response_parts.append(
                    f"Les autres entreprises de l'√©chantillon pr√©sentent des niveaux de maturit√© plus variables, "
                    f"avec des scores de confiance s'√©chelonnant entre {company_scores[-1][2]:.1%} et "
                    f"{company_scores[1][2]:.1%}. Cette h√©t√©rog√©n√©it√© dans la qualit√© des donn√©es et l'√©tendue "
                    f"de la couverture met en lumi√®re des diff√©rences significatives dans les processus de "
                    f"collecte, les ressources allou√©es et la priorisation strat√©gique des enjeux ESG au sein "
                    f"des organisations. Ces √©carts offrent des opportunit√©s d'apprentissage mutuel et de "
                    f"partage de bonnes pratiques entre les diff√©rentes entit√©s."
                )
        
        # Recommandations strat√©giques
        response_parts.append(
            "Pour progresser collectivement vers l'excellence ESG, les entreprises gagneraient √† mettre "
            "en place des m√©canismes de partage d'exp√©riences et de bonnes pratiques, particularly en "
            "mati√®re de m√©thodologies de mesure d'impact et de processus de reporting transparent. "
            "L'harmonisation progressive des approches de collecte, dans le respect des sp√©cificit√©s "
            "sectorielles, faciliterait les comparaisons intersectorielles et renforcerait la cr√©dibilit√© "
            "globale des engagements ESG. Par ailleurs, l'adoption de technologies avanc√©es d'analyse "
            "de donn√©es pourrait significativement am√©liorer l'efficacit√© des processus de reporting "
            "tout en augmentant la fiabilit√© des informations produites."
        )
        
        return "\n\n".join(response_parts)

# Initialisation du chatbot
esg_chatbot = ESGIntelligentChatbot()

# =============================================================================
# FONCTIONS POUR UPLOAD DE PDF DANS LE CHAT
# =============================================================================

def process_pdf_for_chat(pdf_path, kpi_embeddings, all_kpis, kpi_df, min_confidence=0.3):
    """Version simplifi√©e pour le traitement rapide de PDF dans le chat"""
    logger.info(f"Traitement rapide du PDF pour le chat: {os.path.basename(pdf_path)}")
    
    text = extract_text_from_pdf(pdf_path)
    
    if not text or len(text.strip()) < 100:
        logger.warning(f"Peu de texte extrait du PDF pour le chat")
        return []
    
    if not all_kpis or kpi_embeddings is None:
        return []
    
    # Traitement acc√©l√©r√© avec seuil de confiance r√©duit
    relevant_kpis = find_relevant_kpis(text, kpi_embeddings, all_kpis, threshold=0.3)
    
    results = []
    
    for kpi_name, matches in relevant_kpis.items():
        matches_sorted = sorted(matches, key=lambda x: x['score'], reverse=True)
        
        for match in matches_sorted[:2]:  # Limiter √† 2 meilleures correspondances
            sentence = match['sentence']
            values = extract_kpi_values(sentence, kpi_name)
            
            for val in values[:1]:  # Prendre seulement la premi√®re valeur
                topic = "Unknown"
                topic_fr = "Inconnu"
                
                try:
                    if hasattr(kpi_df, 'columns') and len(kpi_df.columns) > 0:
                        kpi_matches = []
                        for col_idx in range(min(2, len(kpi_df.columns))):
                            if kpi_name in kpi_df.iloc[:, col_idx].values:
                                kpi_matches = kpi_df[kpi_df.iloc[:, col_idx] == kpi_name]
                                break
                        
                        if not kpi_matches.empty:
                            row = kpi_matches.iloc[0]
                            if len(kpi_df.columns) > 2:
                                topic = str(row.iloc[2]) if pd.notna(row.iloc[2]) else "Unknown"
                            if len(kpi_df.columns) > 3:
                                topic_fr = str(row.iloc[3]) if pd.notna(row.iloc[3]) else "Inconnu"
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur m√©tadonn√©es KPI: {e}")
                
                result_item = {
                    'kpi_name': kpi_name,
                    'value': val['value'],
                    'unit': val['unit'],
                    'source_file': os.path.basename(pdf_path),
                    'topic': topic,
                    'topic_fr': topic_fr,
                    'confidence': match['score'],
                    'extraction_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                results.append(result_item)
    
    filtered_results = filter_results(results, min_confidence)
    logger.info(f"{len(filtered_results)} KPIs extraits pour le chat")
    
    return filtered_results

# =============================================================================
# NOUVELLE ROUTE POUR UPLOAD DE PDF DANS LE CHAT
# =============================================================================

@app.route('/api/chat-upload-pdf', methods=['POST'])
def chat_upload_pdf():
    """Endpoint pour uploader un PDF directement dans le chat"""
    try:
        if 'pdf_file' not in request.files or 'kpi_file' not in request.files:
            return jsonify({"error": "Fichier PDF et fichier KPI requis"}), 400
        
        pdf_file = request.files['pdf_file']
        kpi_file = request.files['kpi_file']
        
        if pdf_file.filename == '' or kpi_file.filename == '':
            return jsonify({"error": "Aucun fichier s√©lectionn√©"}), 400
        
        if not (allowed_file(pdf_file.filename) and allowed_file(kpi_file.filename)):
            return jsonify({"error": "Type de fichier non autoris√©"}), 400
        
        # Sauvegarder les fichiers temporairement
        pdf_filename = secure_filename(f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{pdf_file.filename}")
        kpi_filename = secure_filename(f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{kpi_file.filename}")
        
        pdf_path = os.path.join(app.config['UPLOAD_FOLDER'], pdf_filename)
        kpi_path = os.path.join(app.config['UPLOAD_FOLDER'], kpi_filename)
        
        pdf_file.save(pdf_path)
        kpi_file.save(kpi_path)
        
        print(f"=== UPLOAD PDF CHAT ===")
        print(f"PDF: {pdf_filename}")
        print(f"KPI: {kpi_filename}")
        
        # Charger les KPIs
        try:
            kpi_df, kpi_list, kpi_list_fr, kpi_embeddings, all_kpis = load_kpi_list(kpi_path)
            
            if len(all_kpis) == 0:
                return jsonify({"error": "Aucun KPI trouv√© dans le fichier"}), 400
                
        except Exception as e:
            print(f"‚ùå Erreur chargement fichier KPI: {e}")
            return jsonify({"error": f"Erreur chargement fichier KPI: {str(e)}"}), 400
        
        # Traitement rapide du PDF
        try:
            extracted_kpis = process_pdf_for_chat(pdf_path, kpi_embeddings, all_kpis, kpi_df, min_confidence=0.3)
        except Exception as e:
            print(f"‚ùå Erreur traitement PDF: {e}")
            return jsonify({"error": f"Erreur traitement PDF: {str(e)}"}), 500
        
        # Nettoyer les fichiers temporaires
        try:
            os.remove(pdf_path)
            os.remove(kpi_path)
        except:
            pass
        
        # Pr√©parer la r√©ponse
        response_data = {
            "success": True,
            "pdf_name": pdf_filename,
            "kpis_extracted": len(extracted_kpis),
            "extracted_data": extracted_kpis,
            "summary": {
                "total_kpis": len(extracted_kpis),
                "high_confidence": len([k for k in extracted_kpis if k.get('confidence', 0) > 0.7]),
                "domains": list(set(k.get('topic_fr', 'Inconnu') for k in extracted_kpis))
            }
        }
        
        print(f"‚úÖ PDF trait√© pour le chat: {len(extracted_kpis)} KPIs extraits")
        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"Erreur upload PDF chat: {e}")
        return jsonify({"error": "Erreur lors du traitement du PDF"}), 500

# =============================================================================
# ROUTE CHAT AVEC SUPPORT PDF AM√âLIOR√âE
# =============================================================================

@app.route('/api/esg-chat', methods=['POST'])
def esg_chat():
    """Endpoint pour le chatbot ESG intelligent avec support des PDF upload√©s"""
    try:
        data = request.get_json() or {}
        user_message = data.get('message', '').strip()
        company_name = data.get('company_name')
        pdf_data = data.get('pdf_data')  # Donn√©es PDF extraites
        
        if not user_message:
            return jsonify({"error": "Message vide"}), 400
        
        # Charger les donn√©es existantes
        df = load_existing_results()
        
        # Si des donn√©es PDF sont fournies, les int√©grer
        if pdf_data and isinstance(pdf_data, list):
            temp_df = pd.DataFrame(pdf_data)
            if not temp_df.empty:
                df = pd.concat([df, temp_df], ignore_index=True)
                print(f"üìÑ Donn√©es PDF int√©gr√©es: {len(pdf_data)} KPIs")
        
        # Filtrer par entreprise si sp√©cifi√©e
        if company_name:
            company_data = df[df['source_file'] == company_name]
        else:
            company_data = df
        
        # Pr√©parer les donn√©es pour l'analyse
        company_info = {}
        if company_name:
            company_info = {
                'entreprise': company_name,
                'total_kpis': len(company_data),
                'domaine_principal': company_data['topic_fr'].mode().iloc[0] if not company_data.empty and 'topic_fr' in company_data.columns else 'Non sp√©cifi√©'
            }
        elif pdf_data:
            # Utiliser les donn√©es du PDF comme contexte
            company_info = {
                'entreprise': 'Document PDF upload√©',
                'total_kpis': len(pdf_data),
                'domaine_principal': 'Analyse en temps r√©el'
            }
        
        # G√©n√©rer la r√©ponse intelligente et d√©taill√©e
        ai_response = esg_chatbot.generate_esg_insight(company_data, company_info, user_message)
        
        return jsonify({
            "response": ai_response,
            "company": company_name or "PDF Upload√©",
            "ai_used": esg_chatbot.ollama_available,
            "pdf_data_included": pdf_data is not None,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Erreur chat ESG: {e}")
        return jsonify({"error": "Erreur lors du traitement de votre requ√™te"}), 500

# =============================================================================
# FONCTIONS EXISTANTES (conserv√©es pour compatibilit√©)
# =============================================================================

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def safe_read_csv(file_path):
    try:
        return pd.read_csv(file_path)
    except pd.errors.ParserError:
        try:
            return pd.read_csv(file_path, on_bad_lines='skip', engine='python')
        except TypeError:
            return pd.read_csv(file_path, error_bad_lines=False, engine='python')
    except Exception as e:
        logger.error(f"Error reading CSV: {e}")
        return pd.DataFrame()

def load_existing_results():
    if os.path.exists(OUTPUT_CSV):
        try:
            existing_df = safe_read_csv(OUTPUT_CSV)
            logger.info(f"Chargement de {len(existing_df)} KPIs existants")
            return existing_df
        except Exception as e:
            logger.error(f"Erreur lors du chargement des r√©sultats existants: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def save_results(all_results):
    if not all_results.empty:
        try:
            all_results.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
            all_results.to_excel(OUTPUT_EXCEL, index=False)
            logger.info(f"R√©sultats sauvegard√©s: {len(all_results)} KPIs")
            return True
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {e}")
            return False
    return False

def load_kpi_list(file_path):
    file_extension = os.path.splitext(file_path)[1].lower()
    
    if file_extension == '.csv':
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252']
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, sep=';', encoding=encoding)
                break
            except UnicodeDecodeError:
                continue
        else:
            raise ValueError("Impossible de d√©coder le fichier CSV")
    
    elif file_extension in ['.xlsx', '.xls']:
        df = pd.read_excel(file_path)
    
    else:
        raise ValueError("Format de fichier non support√©")
    
    print(f"Colonnes disponibles: {list(df.columns)}")
    print(f"Shape du DataFrame: {df.shape}")
    
    if 'kpi_name' in df.columns and 'value' in df.columns:
        print("Fichier de r√©sultats existant d√©tect√©")
        kpi_list = df['kpi_name'].dropna().unique().tolist()
        kpi_list_fr = []
    else:
        kpi_name_col = None
        kpi_name_fr_col = None
        
        for col in df.columns:
            col_lower = col.lower()
            if 'kpi' in col_lower and 'name' in col_lower and 'fr' not in col_lower:
                kpi_name_col = col
            elif 'kpi' in col_lower and 'name' in col_lower and 'fr' in col_lower:
                kpi_name_fr_col = col
            elif 'name' in col_lower and kpi_name_col is None:
                kpi_name_col = col
            elif 'nom' in col_lower and kpi_name_fr_col is None:
                kpi_name_fr_col = col
        
        if kpi_name_col is None and len(df.columns) > 0:
            kpi_name_col = df.columns[0]
        if kpi_name_fr_col is None and len(df.columns) > 1:
            kpi_name_fr_col = df.columns[1]
        
        print(f"Colonne KPI anglais: {kpi_name_col}")
        print(f"Colonne KPI fran√ßais: {kpi_name_fr_col}")
        
        kpi_list = df[kpi_name_col].dropna().unique().tolist() if kpi_name_col else []
        kpi_list_fr = df[kpi_name_fr_col].dropna().unique().tolist() if kpi_name_fr_col else []
    
    print(f"KPIs anglais charg√©s: {len(kpi_list)}")
    print(f"KPIs fran√ßais charg√©s: {len(kpi_list_fr)}")
    
    all_kpis = kpi_list + kpi_list_fr
    if all_kpis:
        kpi_embeddings = kpi_model.encode(all_kpis, convert_to_tensor=True)
    else:
        kpi_embeddings = None
    
    return df, kpi_list, kpi_list_fr, kpi_embeddings, all_kpis

def extract_text_from_pdf(pdf_path):
    text_content = ""
    
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    text_content += text + "\n"
                
                tables = page.extract_tables()
                for table in tables:
                    for row in table:
                        text_content += " | ".join(str(cell) for cell in row if cell is not None) + "\n"
                    text_content += "\n"
    except Exception as e:
        logger.error(f"Erreur avec pdfplumber: {e}")
    
    if len(text_content.strip()) < 100:
        try:
            doc = fitz.open(pdf_path)
            for page in doc:
                text_content += page.get_text("text") + "\n"
        except Exception as e:
            logger.error(f"Erreur avec PyMuPDF: {e}")
    
    return text_content

def clean_text(text):
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        if re.match(r'^\s*\d+\s*$', line):
            continue
        if re.match(r'^.*www\.\w+\.com.*$', line):
            continue
        if len(line.strip()) < 5:
            continue
        cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)

def split_text_into_chunks(text, max_chars=500000):
    if len(text) <= max_chars:
        return [text]
    
    chunks = []
    paragraphs = text.split('\n\n')
    
    current_chunk = ""
    for paragraph in paragraphs:
        if len(current_chunk) + len(paragraph) < max_chars:
            current_chunk += paragraph + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = paragraph + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk)
    
    if any(len(chunk) > max_chars for chunk in chunks):
        refined_chunks = []
        for chunk in chunks:
            if len(chunk) <= max_chars:
                refined_chunks.append(chunk)
            else:
                sentences = re.split(r'[.!?]+', chunk)
                current_refined = ""
                for sentence in sentences:
                    if len(current_refined) + len(sentence) < max_chars:
                        current_refined += sentence + ". "
                    else:
                        if current_refined:
                            refined_chunks.append(current_refined)
                        current_refined = sentence + ". "
                if current_refined:
                    refined_chunks.append(current_refined)
        chunks = refined_chunks
    
    return chunks

def find_relevant_kpis(text, kpi_embeddings, all_kpis, threshold=0.4):
    if not all_kpis or kpi_embeddings is None:
        return {}
        
    cleaned_text = clean_text(text)
    
    print(f"Texte nettoy√©: {len(cleaned_text)} caract√®res")
    
    if len(cleaned_text) > 1000000:
        chunks = split_text_into_chunks(cleaned_text)
        print(f"Texte divis√© en {len(chunks)} chunks")
    else:
        chunks = [cleaned_text]
    
    relevant_kpis = defaultdict(list)
    
    for chunk_idx, chunk in enumerate(chunks):
        print(f"Traitement du chunk {chunk_idx + 1}/{len(chunks)}")
        
        try:
            if len(chunk) > 10000:
                sentences = re.split(r'[.!?]+', chunk)
                sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
            else:
                doc = nlp(chunk)
                sentences = [sent.text for sent in doc.sents if len(sent.text) > 20]
        except Exception as e:
            print(f"Erreur segmentation: {e}")
            sentences = re.split(r'[.!?]+', chunk)
            sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
        
        print(f"Chunk {chunk_idx + 1}: {len(sentences)} phrases √† traiter")
        
        for i, sentence in enumerate(sentences):
            if i % 50 == 0 and i > 0:
                print(f"  Trait√© {i}/{len(sentences)} phrases...")
                
            try:
                sentence_embedding = kpi_model.encode(sentence, convert_to_tensor=True)
                cos_scores = util.pytorch_cos_sim(sentence_embedding, kpi_embeddings)[0]
                top_results = np.argsort(-cos_scores.cpu().numpy())[:3]
                
                for idx in top_results:
                    if cos_scores[idx] > threshold:
                        kpi_name = all_kpis[idx]
                        if not any(match['sentence'] == sentence for match in relevant_kpis[kpi_name]):
                            relevant_kpis[kpi_name].append({
                                'sentence': sentence,
                                'score': float(cos_scores[idx])
                            })
            except Exception as e:
                print(f"Erreur traitement phrase: {e}")
                continue
    
    print(f"KPIs pertinents trouv√©s: {len(relevant_kpis)}")
    for kpi_name, matches in relevant_kpis.items():
        print(f"  - {kpi_name}: {len(matches)} correspondances")
    
    return relevant_kpis

def is_value_coherent(kpi_name, value, unit):
    kpi_lower = kpi_name.lower()
    
    high_value_kpis = ['emission', 'ghg', 'co2', 'nox', 'sox', 'energy', 'water', 'waste', 'consumption']
    percentage_kpis = ['rate', 'ratio', 'percentage', 'coverage', 'compliance', 'approval']
    
    if any(term in kpi_lower for term in high_value_kpis) and unit == '%' and value < 1:
        return False
        
    if any(term in kpi_lower for term in percentage_kpis) and unit != '%' and value > 1000:
        return False
        
    return True

def extract_kpi_values(text, kpi_name):
    patterns = [
        r"(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\s*(?:tons?|tonnes|t|%|kg|kWh|CO2|CO‚ÇÇ|ppm|ppb|¬µg/m¬≥|mg/m¬≥|employees|people|‚Ç¨|EUR|USD|\$|m¬≥|MWh|GWh|TJ)",
        r"(\d{1,3}(?:,\d{3})*(?:\.\d+)?\%)(?:\s|$)",
        r"(?:is|was|are|were|:|\=)\s*(\d{1,3}(?:,\d{3})*(?:\.\d+)?)",
        r"(?:value of|rate of|amount of|total|reduction of|approximately|about)\s*(\d{1,3}(?:,\d{3})*(?:\.\d+)?)",
        r"\b(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\s*(?:million|billion|thousand)?\s*(?:tons?|tonnes|percent|%)?"
    ]
    
    values = []
    seen_values = set()
    
    for pattern in patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            value_str = match.group(1).replace(',', '')
            try:
                multiplier = 1
                if re.search(r'million', match.group(0), re.IGNORECASE):
                    multiplier = 1000000
                elif re.search(r'billion', match.group(0), re.IGNORECASE):
                    multiplier = 1000000000
                elif re.search(r'thousand', match.group(0), re.IGNORECASE):
                    multiplier = 1000
                
                numeric_value = float(value_str) * multiplier if '.' in value_str else int(value_str) * multiplier
                unit = determine_unit(text, kpi_name)
                
                value_id = f"{numeric_value}_{unit}"
                
                if (value_id not in seen_values and 
                    is_value_coherent(kpi_name, numeric_value, unit)):
                    values.append({
                        'value': numeric_value,
                        'unit': unit
                    })
                    seen_values.add(value_id)
            except ValueError:
                continue
    
    return values

def determine_unit(text, kpi_name):
    unit_patterns = {
        r'tons?|tonnes|tCO2e|t CO2e': 'tons',
        r'kg|kilograms': 'kg',
        r'%|percent|percentage': '%',
        r'kWh|kilowatt-hours': 'kWh',
        r'MWh|megawatt-hours': 'MWh',
        r'GWh|gigawatt-hours': 'GWh',
        r'CO2|CO‚ÇÇ|carbon dioxide': 'tCO2e',
        r'ppm|parts per million': 'ppm',
        r'employees|workers|people': 'people',
        r'‚Ç¨|EUR|USD|\$|dollars': 'currency',
        r'm¬≥|cubic meters': 'm¬≥'
    }
    
    for pattern, u in unit_patterns.items():
        if re.search(pattern, text, re.IGNORECASE):
            return u
    
    kpi_lower = kpi_name.lower()
    if any(term in kpi_lower for term in ['rate', 'ratio', 'percentage', 'coverage', 'reduction']):
        return '%'
    elif any(term in kpi_lower for term in ['emission', 'ghg', 'co2', 'carbon']):
        return 'tCO2e'
    elif any(term in kpi_lower for term in ['energy', 'consumption', 'electricity']):
        return 'kWh'
    elif any(term in kpi_lower for term in ['water', 'usage']):
        return 'm¬≥'
    
    return 'unknown'

def filter_results(results, min_confidence=0.3):
    filtered = []
    seen = set()
    
    results_sorted = sorted(results, key=lambda x: x['confidence'], reverse=True)
    
    for result in results_sorted:
        identifier = f"{result['kpi_name']}_{result['value']}_{result['unit']}_{result['source_file']}"
        
        if (identifier not in seen and 
            result['confidence'] >= min_confidence):
            filtered.append(result)
            seen.add(identifier)
    
    kpi_groups = defaultdict(list)
    for result in filtered:
        kpi_groups[result['kpi_name']].append(result)
    
    final_results = []
    for kpi_name, occurrences in kpi_groups.items():
        best_occurrence = max(occurrences, key=lambda x: x['confidence'])
        final_results.append(best_occurrence)
    
    return final_results

def process_pdf(pdf_path, kpi_embeddings, all_kpis, kpi_df, min_confidence=0.3):
    logger.info(f"Traitement de {os.path.basename(pdf_path)}...")
    
    text = extract_text_from_pdf(pdf_path)
    
    print(f"=== DEBUG EXTRACTION ===")
    print(f"Fichier: {os.path.basename(pdf_path)}")
    print(f"Texte extrait: {len(text)} caract√®res")
    
    if not text or len(text.strip()) < 100:
        logger.warning(f"Peu de texte extrait de {pdf_path}")
        print("‚ùå ERREUR: Texte insuffisant")
        return []
    
    debug_dir = "debug_texts"
    os.makedirs(debug_dir, exist_ok=True)
    debug_file = os.path.join(debug_dir, f"debug_{os.path.basename(pdf_path)}.txt")
    with open(debug_file, 'w', encoding='utf-8') as f:
        f.write(text[:5000] + "\n[...]")
    
    print(f"Texte debug sauvegard√©: {debug_file}")
    
    if not all_kpis or kpi_embeddings is None:
        print("‚ùå AUCUN KPI DISPONIBLE - V√©rifiez le fichier KPI")
        return []
    
    relevant_kpis = find_relevant_kpis(text, kpi_embeddings, all_kpis, threshold=0.4)
    
    results = []
    
    for kpi_name, matches in relevant_kpis.items():
        print(f"Traitement KPI: {kpi_name} ({len(matches)} correspondances)")
        
        matches_sorted = sorted(matches, key=lambda x: x['score'], reverse=True)
        
        for match in matches_sorted[:3]:
            sentence = match['sentence']
            values = extract_kpi_values(sentence, kpi_name)
            
            print(f"  Phrase: '{sentence[:100]}...' -> {len(values)} valeurs")
            
            for val in values:
                topic = "Unknown"
                topic_fr = "Inconnu"
                score = "Unknown"
                
                try:
                    if hasattr(kpi_df, 'columns') and len(kpi_df.columns) > 0:
                        kpi_matches = []
                        for col_idx in range(min(2, len(kpi_df.columns))):
                            if kpi_name in kpi_df.iloc[:, col_idx].values:
                                kpi_matches = kpi_df[kpi_df.iloc[:, col_idx] == kpi_name]
                                break
                        
                        if not kpi_matches.empty:
                            row = kpi_matches.iloc[0]
                            if len(kpi_df.columns) > 2:
                                topic = str(row.iloc[2]) if pd.notna(row.iloc[2]) else "Unknown"
                            if len(kpi_df.columns) > 3:
                                topic_fr = str(row.iloc[3]) if pd.notna(row.iloc[3]) else "Inconnu"
                            if len(kpi_df.columns) > 4:
                                score_val = row.iloc[4]
                                score = str(score_val) if pd.notna(score_val) else "Unknown"
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des m√©tadonn√©es KPI: {e}")
                
                result_item = {
                    'kpi_name': kpi_name,
                    'value': val['value'],
                    'unit': val['unit'],
                    'source_file': os.path.basename(pdf_path),
                    'topic': topic,
                    'topic_fr': topic_fr,
                    'score': score,
                    'confidence': match['score'],
                    'extraction_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                results.append(result_item)
                print(f"  ‚úÖ KPI extrait: {kpi_name} = {val['value']} {val['unit']} (confiance: {match['score']:.3f})")
    
    filtered_results = filter_results(results, min_confidence)
    logger.info(f"{len(filtered_results)} KPIs valides apr√®s filtrage")
    
    if filtered_results:
        print(f"üéâ EXTRACTION R√âUSSIE: {len(filtered_results)} KPIs uniques extraits")
    else:
        print("‚ùå AUCUN KPI EXTRACT√â - V√©rifiez le fichier KPI et le contenu du PDF")
    
    return filtered_results

# =============================================================================
# ROUTES API EXISTANTES
# =============================================================================

@app.route('/api/health', methods=['GET'])
def health_check():
    return jsonify({"status": "healthy", "message": "ESG KPI Extractor API is running"})

@app.route('/api/process', methods=['POST'])
def process_pdf_route():
    try:
        if 'kpi_file' not in request.files or 'pdf_file' not in request.files:
            return jsonify({"error": "KPI file and PDF file are required"}), 400
        
        kpi_file = request.files['kpi_file']
        pdf_file = request.files['pdf_file']
        min_confidence = float(request.form.get('min_confidence', 0.3))
        rerun_if_exists = request.form.get('rerun_if_exists', 'false').lower() == 'true'
        
        if kpi_file.filename == '' or pdf_file.filename == '':
            return jsonify({"error": "No selected file"}), 400
        
        if not (allowed_file(kpi_file.filename) and allowed_file(pdf_file.filename)):
            return jsonify({"error": "Invalid file type"}), 400
        
        kpi_filename = secure_filename(kpi_file.filename)
        pdf_filename = secure_filename(pdf_file.filename)
        
        kpi_path = os.path.join(app.config['UPLOAD_FOLDER'], kpi_filename)
        pdf_path = os.path.join(app.config['UPLOAD_FOLDER'], pdf_filename)
        
        kpi_file.save(kpi_path)
        pdf_file.save(pdf_path)
        
        print(f"=== D√âBUT TRAITEMENT ===")
        print(f"KPI file: {kpi_filename}")
        print(f"PDF file: {pdf_filename}")
        print(f"Min confidence: {min_confidence}")
        
        existing_results = load_existing_results()
        
        if (not existing_results.empty and 
            pdf_filename in existing_results['source_file'].values and 
            not rerun_if_exists):
            print("‚ö†Ô∏è PDF d√©j√† trait√©")
            return jsonify({
                "warning": f"PDF {pdf_filename} was already processed",
                "processed": False
            }), 200
        
        print("Chargement des KPIs...")
        try:
            kpi_df, kpi_list, kpi_list_fr, kpi_embeddings, all_kpis = load_kpi_list(kpi_path)
            
            if len(all_kpis) == 0:
                return jsonify({"error": "No KPIs found in the KPI file"}), 400
                
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du fichier KPI: {e}")
            return jsonify({"error": f"Error loading KPI file: {str(e)}"}), 400
        
        print("Traitement du PDF...")
        try:
            new_results = process_pdf(pdf_path, kpi_embeddings, all_kpis, kpi_df, min_confidence)
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement du PDF: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return jsonify({"error": f"Error processing PDF: {str(e)}"}), 500
        
        response_data = {
            "processed": True,
            "pdf_name": pdf_filename,
            "kpis_loaded": len(all_kpis),
            "new_kpis_extracted": len(new_results),
            "results": new_results
        }
        
        if new_results:
            try:
                if existing_results.empty:
                    all_results = pd.DataFrame(new_results)
                else:
                    new_df = pd.DataFrame(new_results)
                    all_results = pd.concat([existing_results, new_df], ignore_index=True)
                    all_results = all_results.drop_duplicates(
                        subset=['kpi_name', 'value', 'unit', 'source_file'], 
                        keep='last'
                    )
                
                save_success = save_results(all_results)
                if save_success:
                    response_data["total_kpis"] = len(all_results)
                    print(f"üíæ Donn√©es sauvegard√©es: {len(all_results)} KPIs au total")
                else:
                    print("‚ùå Erreur sauvegarde")
            except Exception as e:
                print(f"‚ùå Erreur lors de la sauvegarde: {e}")
        
        try:
            os.remove(kpi_path)
            os.remove(pdf_path)
        except:
            pass
        
        print(f"=== FIN TRAITEMENT: {len(new_results)} nouveaux KPIs ===")
        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"Error processing PDF: {e}")
        import traceback
        print(f"‚ùå ERREUR: {traceback.format_exc()}")
        return jsonify({"error": str(e)}), 500

# Routes existantes conserv√©es
@app.route('/api/esg-benchmark', methods=['POST'])
def esg_benchmark():
    # Impl√©mentation existante...
    pass

@app.route('/api/esg-recommendations', methods=['POST'])
def esg_recommendations():
    # Impl√©mentation existante...
    pass

@app.route('/api/chatbot-status', methods=['GET'])
def chatbot_status():
    # Impl√©mentation existante...
    pass

@app.route('/api/statistics', methods=['GET'])
def get_statistics():
    # Impl√©mentation existante...
    pass

@app.route('/api/dashboard', methods=['GET'])
def get_dashboard_data():
    # Impl√©mentation existante...
    pass

@app.route('/api/companies', methods=['GET'])
def get_companies():
    # Impl√©mentation existante...
    pass

@app.route('/api/company/<company_name>', methods=['GET'])
def get_company_data(company_name):
    # Impl√©mentation existante...
    pass

@app.route('/api/comparison', methods=['GET'])
def get_comparison_data():
    # Impl√©mentation existante...
    pass

@app.route('/api/export/csv', methods=['GET'])
def export_csv():
    # Impl√©mentation existante...
    pass

@app.route('/api/export/excel', methods=['GET'])
def export_excel():
    # Impl√©mentation existante...
    pass

@app.route('/api/export/company/<company_name>', methods=['GET'])
def export_company_data(company_name):
    # Impl√©mentation existante...
    pass

if __name__ == '__main__':
    print("üöÄ D√©marrage de l'API ESG Analytics avec Chatbot Intelligent...")
    print("=" * 60)
    print("üìä Fonctionnalit√©s ESG Avanc√©es:")
    print("  ‚úÖ Extraction automatique de KPIs ESG")
    print("  ü§ñ Chatbot expert avec r√©ponses d√©taill√©es")
    print("  üìÑ Upload de PDF directement dans le chat")
    print("  üìà Benchmarking approfondi entre entreprises")
    print("  üí° Recommandations strat√©giques personnalis√©es")
    print("=" * 60)
    print(f"üîß Chatbot ESG: {'‚úÖ MODE AVANC√â (Ollama)' if esg_chatbot.ollama_available else '‚ö†Ô∏è MODE STANDARD'}")
    print(f"üåê URL: http://localhost:5000")
    print("=" * 60)
    
    app.run(debug=True, host='0.0.0.0', port=5000)